{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis-RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0XQHl4Dn8UjwvVUkBySuU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrightonOtieno/RNN-Sentiment-Analysis/blob/master/Sentiment_Analysis_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mwcXts-CsyT",
        "colab_type": "text"
      },
      "source": [
        "# Determine Whether a movie review is good sentiment or bad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "relzWpl7C9rJ",
        "colab_type": "text"
      },
      "source": [
        "### Each (unique)word is encoded by a number  representing how common it is in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMyuiutnC5eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import numpy as np\n",
        "import keras\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQMkRymJDvx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set some parameters\n",
        "VOCAB_SIZE = 88584\n",
        "MAXLEN = 250 # each movie review has differnt lengths(shorter ones we  padd with 0 longer ones we truncate)\n",
        "BATCH_SIZE = 64\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SOb2VV1Eu3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data,train_labels),(test_data,test_label) = imdb.load_data(num_words=VOCAB_SIZE)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYzcZHoYFHWB",
        "colab_type": "text"
      },
      "source": [
        "* **lets have a look at  a single movie review**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE0BfDmiFAje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a512d4b4-1647-43e5-dcdc-693a271d63b8"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTLyehBIFFGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d3b2984-21dc-4ab9-a0f2-fffb6d094a20"
      },
      "source": [
        "len(train_data[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7wGZZ2kFk2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "94aef478-4145-4347-b620-fba90da6fbe3"
      },
      "source": [
        "print(train_labels[0])\n",
        "print(train_labels[2])\n",
        "print(train_labels[10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bm9wpXSGuVm",
        "colab_type": "text"
      },
      "source": [
        "# more preprocessing \n",
        "### making the lengths uniform\n",
        "* MAX_LENGTH = 250 WORDS\n",
        "* if the length is shorter than 250  we add 0's to the left(padding)\n",
        "* if the length is longer  than 250 words we cut of the extras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A4XPZWLHcVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = sequence.pad_sequences(train_data,MAXLEN)\n",
        "test_data = sequence.pad_sequences(test_data,MAXLEN)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PErKreXpGGJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ec9dfbe3-f18c-4710-8269-9aac19a259d5"
      },
      "source": [
        "print(train_data[1])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     1   194  1153   194  8255    78   228     5     6  1463  4369\n",
            "  5012   134    26     4   715     8   118  1634    14   394    20    13\n",
            "   119   954   189   102     5   207   110  3103    21    14    69   188\n",
            "     8    30    23     7     4   249   126    93     4   114     9  2300\n",
            "  1523     5   647     4   116     9    35  8163     4   229     9   340\n",
            "  1322     4   118     9     4   130  4901    19     4  1002     5    89\n",
            "    29   952    46    37     4   455     9    45    43    38  1543  1905\n",
            "   398     4  1649    26  6853     5   163    11  3215 10156     4  1153\n",
            "     9   194   775     7  8255 11596   349  2637   148   605 15358  8003\n",
            "    15   123   125    68 23141  6853    15   349   165  4362    98     5\n",
            "     4   228     9    43 36893  1157    15   299   120     5   120   174\n",
            "    11   220   175   136    50     9  4373   228  8255     5 25249   656\n",
            "   245  2350     5     4  9837   131   152   491    18 46151    32  7464\n",
            "  1212    14     9     6   371    78    22   625    64  1382     9     8\n",
            "   168   145    23     4  1690    15    16     4  1355     5    28     6\n",
            "    52   154   462    33    89    78   285    16   145    95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52N6tOJII6au",
        "colab_type": "text"
      },
      "source": [
        "# CREATING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX_14b-CIx_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(VOCAB_SIZE,32),\n",
        "                             tf.keras.layers.LSTM(32),\n",
        "                             tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6YYYEfLLuFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6515975b-53ab-4d4a-82a8-1e142b461b9a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          2834688   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DnquMVFNM4z",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCAlZlV_LzJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d9f80b22-03ef-413f-c459-57e38d2765aa"
      },
      "source": [
        "model.compile(loss = 'binary_crossentropy',optimizer = 'rmsprop',metrics = ['acc'] )\n",
        "\n",
        "history =  model.fit(train_data,train_labels,epochs=10,validation_split=0.2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 0.4164 - acc: 0.8101 - val_loss: 0.2961 - val_acc: 0.8776\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 0.2324 - acc: 0.9110 - val_loss: 0.2978 - val_acc: 0.8824\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.1802 - acc: 0.9330 - val_loss: 0.2694 - val_acc: 0.8922\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.1479 - acc: 0.9488 - val_loss: 0.3084 - val_acc: 0.8874\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.1261 - acc: 0.9570 - val_loss: 0.2888 - val_acc: 0.8800\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.1052 - acc: 0.9641 - val_loss: 0.3012 - val_acc: 0.8834\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.0942 - acc: 0.9689 - val_loss: 0.3348 - val_acc: 0.8888\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.0823 - acc: 0.9724 - val_loss: 0.3839 - val_acc: 0.8718\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.0720 - acc: 0.9770 - val_loss: 0.3737 - val_acc: 0.8852\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.0631 - acc: 0.9791 - val_loss: 0.3957 - val_acc: 0.8836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s5d5sv5S019",
        "colab_type": "text"
      },
      "source": [
        "#  Evaluating Model on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwIWFXKbN36y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23510888-ef4a-4c5a-bd88-5518aa2d15ac"
      },
      "source": [
        "results = model.evaluate(test_data,test_label)\n",
        "print(results)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 13s 16ms/step - loss: 0.4738 - acc: 0.8568\n",
            "[0.4737767279148102, 0.8568000197410583]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiZrMGC-TTD6",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U7BDcGzXqnP",
        "colab_type": "text"
      },
      "source": [
        "* get the imdb Dictionay(with those words)\n",
        "*  function that chops the text into words only\n",
        "* loop through the words \n",
        "* check if the word is in the dictionary \n",
        "* take  its integer representation in the dictionary and place it into a list called (token )\n",
        "* if word is not in dictionary then in the token  list we replace it with 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7atGmpMMTLWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  # chop the review(sentence) into tokens(individual words)\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "\n",
        "  return sequence.pad_sequences([tokens],MAXLEN)[0]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrTWOnMgjUNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b15851f8-25b3-4ad5-a0ac-6463089c0359"
      },
      "source": [
        "text = 'this is a movie i like'\n",
        "encoded = encode_text(text)\n",
        "print(encoded)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0 11  6  3 17 10 37]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiK6E9m5nBwJ",
        "colab_type": "text"
      },
      "source": [
        "## Decode Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfsze96lkEGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_word_index = {value:key for (key,value) in word_index.items()}\n",
        "# loops through all words in vocab get key(integer representation) and value(word)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awdVSUJBwNmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d5736ae-e297-4a9b-845f-9a184afd3af0"
      },
      "source": [
        "def decode_integer(integers):\n",
        "\n",
        "  PAD = 0\n",
        "  text = \" \"\n",
        "\n",
        "  for num in integers:\n",
        "    if num != 0:\n",
        "      text += reverse_word_index[num] + \" \" # gets the word from the dictionary concats it with a space the concat it with (text) to make a sentence\n",
        "\n",
        "  return text[:-1]  # return everything in the sentence except the last character (which is a space) \n",
        "print(decode_integer(encoded))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " this is a movie i like\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1UOpMVH5Aa1",
        "colab_type": "text"
      },
      "source": [
        "# Prediction Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnM6H3395G2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250)) # blank nupy array  filled with 0's and of 250 length(what model expects)\n",
        "  pred[0] = encoded_text # pick first array in the pred (array of arrays) and (set it to the array from encoding function)\n",
        "  results = model.predict(pred)\n",
        "  print(results[0])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kcbK60L6vij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example of positive reviews and negative review\n",
        "positive_review = \"i really really love it its awesome\"\n",
        "negative_review = \" i hate that movie it sucks\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8_iK0717XDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250)) # blank nupy array  filled with 0's and of 250 length(what model expects)\n",
        "  pred[0] = encoded_text # pick first array in the pred (array of arrays) and (set it to the array from encoding function)\n",
        "  results = model.predict(pred)\n",
        "  review_status = results[0][0]\n",
        "  if review_status > 0.5:\n",
        "    print('positive sentiment')\n",
        "  else:\n",
        "    print('negative sentiment')\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2uxplqV-KCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(predict(positive_review))\n",
        "print(predict(negative_review))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}